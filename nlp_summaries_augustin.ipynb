{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ec18c4",
   "metadata": {},
   "source": [
    "### Important : check in \"power options\" of your computer that it does not go into sleep mode after x hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e906663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2f126",
   "metadata": {},
   "source": [
    "### US movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b842b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARACTER_DATA_PATH = './data/character.metadata.tsv'\n",
    "MOVIE_DATA_PATH = './data/movie.metadata.tsv'\n",
    "SUMMARIES_DATA_PATH = './data/plot_summaries.txt'\n",
    "NAME_DATA_PATH = './data/name.clusters.txt'\n",
    "TYPE_DATA_PATH = './data/tvtropes.clusters.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bae4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIE_HEADER = ['Wikipedia_movie_ID','Freebase_movie_ID','Movie_name','Movie_release_date',\n",
    "                'Movie_box_office_revenue','Movie_runtime','Movie_languages','Movie_countries','Movie_genres']\n",
    "\n",
    "movies = pd.read_table(MOVIE_DATA_PATH,header=None,names=MOVIE_HEADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06094a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of US movies : 34408\n"
     ]
    }
   ],
   "source": [
    "def format_dict(x):\n",
    "    n = len(x)\n",
    "    if n==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return ','.join(str(s) for s in list(x.values()))\n",
    "    \n",
    "\n",
    "try :\n",
    "\n",
    "    movies['Movie_genres'] = movies['Movie_genres'].apply(json.loads).apply(format_dict)\n",
    "    movies['Movie_countries'] = movies['Movie_countries'].apply(json.loads).apply(format_dict)\n",
    "    movies['Movie_languages'] = movies['Movie_languages'].apply(json.loads).apply(format_dict)\n",
    "except json.decoder.JSONDecodeError:\n",
    "    print('Data has already been parsed and modified.')\n",
    "    \n",
    "# Keep only American movies\n",
    "us_movies = movies[movies['Movie_countries'].astype(str).str.contains('United States of America')]\n",
    "print(\"Number of US movies : {}\".format(len(us_movies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda655cf",
   "metadata": {},
   "source": [
    "### Summaries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f37d8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33324</th>\n",
       "      <td>26825116</td>\n",
       "      <td>Maria is a white farmer who runs  a failing co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40711</th>\n",
       "      <td>19587744</td>\n",
       "      <td>A 13-year-old boy named Billy runs from home a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>29287983</td>\n",
       "      <td>Junior detective Gray  discovers that the ecce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_movie_ID                                            Summary\n",
       "33324            26825116  Maria is a white farmer who runs  a failing co...\n",
       "40711            19587744  A 13-year-old boy named Billy runs from home a...\n",
       "3544             29287983  Junior detective Gray  discovers that the ecce..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = pd.read_table(SUMMARIES_DATA_PATH,header=None,names=['Wikipedia_movie_ID','Summary'])\n",
    "summaries.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e49fa",
   "metadata": {},
   "source": [
    "### Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab3dd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of US movies with summary : 20788\n"
     ]
    }
   ],
   "source": [
    "us_summaries = us_movies.merge(summaries, how='inner', on=['Wikipedia_movie_ID'])\n",
    "print(\"Number of US movies with summary : {}\".format(len(us_summaries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf0634",
   "metadata": {},
   "source": [
    "### Splitting the dataframe (one different part of the dataframe for each person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834b7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first sort 'us_summaries' to make sure that we are working with movies in the same order before iterating over the rows\n",
    "us_summaries = us_summaries.sort_values(by=['Wikipedia_movie_ID'])\n",
    "\n",
    "# Splitting (note : len(us_summaries) = 20788)\n",
    "#range_for_ben = [0,4000]\n",
    "#range_for_romain = [4000,8000]\n",
    "range_for_augustin = [8000,12000]\n",
    "#range_for_erwann = [12000,16000]\n",
    "#range_for_lucas = [16000,20789]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d87ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_us_summaries = us_summaries[range_for_augustin[0]:range_for_augustin[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912da81",
   "metadata": {},
   "source": [
    "### Vectorization of summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be32a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages to be installed (other installations might be needed, see below)\n",
    "!pip install sentence_transformers\n",
    "!pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eaf82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk import sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import textract\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a3516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\beynes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8305b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6739f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    # Input : the whole text as one string\n",
    "    # Output : mean vector of all the embeddings vectors related to the sentences of the text input, as well as all embeddings\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = text.replace(u'\\xa0', u' ')\n",
    "    text = text.replace(u'\\xc2','')\n",
    "    # Split the whole text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    # Embedding using BERT model (can convert a sentence into a vector of dimension 768)\n",
    "    df_text_sents = pd.Series(sentences)\n",
    "    df_text_embeddings = df_text_sents.map(lambda x: model.encode(x))\n",
    "    # Convert all vectors from reference text into one single vector, by taking the mean\n",
    "    mean_vector = df_text_embeddings.sum() / df_text_embeddings.size\n",
    "    \n",
    "    return(mean_vector,df_text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dfe5fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:10<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "\n",
    "for index,movie in tqdm(split_us_summaries.iterrows(), total=split_us_summaries.shape[0]):\n",
    "    try:\n",
    "        embeddings[movie['Wikipedia_movie_ID']] = text2vec(movie['Summary'])\n",
    "    except:\n",
    "        print(\"An error occurred for movie ID {}\".format(movie['Wikipedia_movie_ID']))\n",
    "\n",
    "# Store embeddings (serialize)\n",
    "with open('embeddings_augustin.pickle', 'wb') as handle:\n",
    "    pickle.dump(embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "436ab97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the embeddings\n",
    "with open('embeddings_augustin.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b901937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
