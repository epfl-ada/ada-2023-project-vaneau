{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import hollywood as hy\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '../../data/'\n",
    "# movies = pd.read_csv(data_dir + 'movies.csv')\n",
    "movies = pd.read_csv('movies_with_flag.csv')\n",
    "movies['production_companies'] = movies['production_companies'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hollywood studios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting hollywood movie studios from https://en.wikipedia.org/wiki/Major_film_studios#Mini-majors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### wikipedia_hollywood_studios\n",
    "The following studios were taken from wikipedia and a list constructed with the compatible studio names in our dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    'Wikipedia name', 'Search term(s) used to construct dataframe'\n",
    "    ------\n",
    "     \n",
    "    'NBCUniversal', (Universal)\n",
    "    'Lucasfilm', (Lucasfilm)\n",
    "    'Paramount Pictures', (Paramount)\n",
    "    'Warner Bros. Pictures', (Warner)\n",
    "    'New Line Cinema ', (New Line Cinema)\n",
    "    'Walt Disney Pictures', (Disney)\n",
    "    '20th Century Studios', (20th)\n",
    "    'Columbia Pictures', (Columbia)\n",
    "    'TriStar Pictures', (TriStar)\n",
    "    'A24 Films', Founded 2012\n",
    "    'Metro-Goldwyn-Mayer', (Metro-Goldwyn)\n",
    "    'Lionsgate Films', (Lionsgate)\n",
    "    'Summit Entertainment', (==)\n",
    "    'STX Films', Founded 2014\n",
    "    'Amblin Entertainment', (==)\n",
    "    'DreamWorks Pictures', (DreamWorks)\n",
    "    'Gaumont Film Company', (Gaumont)\n",
    "    'Pathé Films',(Pathé)\n",
    "    'StudioCanal',(==)\n",
    "    'Nordisk Film', (==)\n",
    "    'Constantin Film', (==)\n",
    "    'Castle Rock Entertainment', (Castle Rock)\n",
    "    'Monogram Pictures', (Monogram)\n",
    "    'Allied Artists Pictures', (Allied Artists)\n",
    "    'New Line Cinema', (==)\n",
    "    'Relativity Media', (==)\n",
    "    'Orion Pictures', (==)\n",
    "    'Revolution Studios', (==)\n",
    "    'Avco Embassy', (Avco)\n",
    "    'The Weinstein Company', (Weinstein)\n",
    "    'Republic Pictures', (Republic)\n",
    "    'FilmDistrict', (==)\n",
    "    'Focus Features', (==)\n",
    "    'PolyGram Filmed Entertainment', (PolyGram)\n",
    "    'Artisan Entertainment', (==)\n",
    "    'Overture Films',(==)\n",
    "    'Summit Entertainment', (==)\n",
    "    'The Cannon Group', (Cannon Group)\n",
    "    'Global Road Entertainment', Founded 2017\n",
    "    'Open Road Films', Founded 2019\n",
    "    'Miramax Films', (Miramax)\n",
    "    'Weintraub Entertainment Group',(==)\n",
    "    'CBS Films', (CBS)\n",
    "    'Alchemy',(==)\n",
    "    'Cinerama Releasing Corporation', (Cinerama)\n",
    "    'National General Corporation', (National General)\n",
    "    'Commonwealth United Corporation',(==)\n",
    "    'ABC Pictures International', (ABC)\n",
    "    'New World Pictures',(==)\n",
    "    'Turner Pictures', (Turner)\n",
    "    'Marvel Studios', (Marvel)\n",
    "    'Pixar Animation Studios', (Pixar)\n",
    "    'The Samuel Goldwyn Company' (Samuel Goldwyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating hollywood studio list from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prep\n",
    "# # creating empty dataframe\n",
    "# valid_entries = pd.DataFrame(columns=['Item', 'Count'])\n",
    "\n",
    "# # filtering our Dataset\n",
    "# filtered_movies = movies[\n",
    "#     (movies['prod_country'] == 'US')\n",
    "#     ]\n",
    "\n",
    "# # count data how often each studio is mentionned in dataset\n",
    "# production_companies = filtered_movies['production_companies'].apply(lambda x: literal_eval(x))\n",
    "# production_companies = production_companies.explode().value_counts()\n",
    "# production_companies = pd.DataFrame(list(production_companies.items()), columns=['Item', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Samuel Goldwyn Productions</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Samuel Goldwyn Company</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Samuel Goldwyn Films</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Item  Count\n",
       "49   Samuel Goldwyn Productions     77\n",
       "177      Samuel Goldwyn Company     25\n",
       "250        Samuel Goldwyn Films     19"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # go through studio names by wikipedia by hand\n",
    "# studio = 'Samuel Goldwyn'\n",
    "# res = production_companies['Item'].str.contains(studio, case=False, na=False)\n",
    "# production_companies[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samuel Goldwyn\n"
     ]
    }
   ],
   "source": [
    "# # append the studios if deemed good\n",
    "# valid_entries = pd.concat([valid_entries, production_companies[res]])\n",
    "# print(studio)\n",
    "\n",
    "# valid_entries.to_csv('hollywood_studios.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing hollywood studio list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe\n",
    "wikipedia_studios_counts = pd.read_csv('./hollywood_studios.csv')\n",
    "wikipedia_studios = wikipedia_studios_counts['Item'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flag in dataframe\n",
    "movies['is_hollywood_wiki'] = movies['production_companies'].apply(lambda x: hy.isInList(x, wikipedia_studios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585668449197861"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(movies[movies['is_hollywood_wiki']]['revenue'].isna()) / len(movies[movies['is_hollywood_wiki']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studios by actors\n",
    "It seems that at least some studios are missing (when checking for angelina jolie for example)\n",
    "\n",
    "created a list from the wikipedia page for the hall of fame: https://de.wikipedia.org/wiki/Hollywood_Walk_of_Fame#cite_note-star_directory-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_movies = us_movies[us_movies['prod_country'] == 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all actors from hall of fame\n",
    "from walk_of_fame import walk_of_fame\n",
    "hof_studios = []\n",
    "\n",
    "for actor in walk_of_fame:\n",
    "    # check if actor is in movie\n",
    "    in_movie = us_movies['actors'].apply(lambda x: actor in x)\n",
    "    production_companies = list(us_movies[in_movie]['production_companies'].explode())\n",
    "    # append to studio list\n",
    "    hof_studios += production_companies\n",
    "\n",
    "# make unique and remove nans\n",
    "hof_studios = list(set(hof_studios))\n",
    "hof_studios = [studio for studio in hof_studios if str(studio) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flag in dataframe\n",
    "movies['is_hollywood_hof'] = movies['production_companies'].apply(lambda x: hy.isInList(x, hof_studios))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20694"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(movies['id_imdb'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = pd.read_table(data_dir + 'character.metadata.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>975900</th>\n",
       "      <th>/m/03vyhn</th>\n",
       "      <th>2001-08-24</th>\n",
       "      <th>Akooshay</th>\n",
       "      <th>1958-08-26</th>\n",
       "      <th>F</th>\n",
       "      <th>1.62</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Wanda De Jesus</th>\n",
       "      <th>42</th>\n",
       "      <th>/m/0bgchxw</th>\n",
       "      <th>/m/0bgcj3x</th>\n",
       "      <th>/m/03wcfv7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Commander Helena Braddock</td>\n",
       "      <td>1949-05-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Pam Grier</td>\n",
       "      <td>52.0</td>\n",
       "      <td>/m/02vdcfp</td>\n",
       "      <td>/m/0bgchnd</td>\n",
       "      <td>/m/0418ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450663</th>\n",
       "      <td>913762</td>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>Elensh</td>\n",
       "      <td>1970-05</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dorothy Elias-Fahn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0kr406c</td>\n",
       "      <td>/m/0kr406h</td>\n",
       "      <td>/m/0b_vcv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450664</th>\n",
       "      <td>913762</td>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>Hibiki</td>\n",
       "      <td>1965-04-12</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jonathan Fahn</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0kr405_</td>\n",
       "      <td>/m/0kr4090</td>\n",
       "      <td>/m/0bx7_j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450665</th>\n",
       "      <td>28308153</td>\n",
       "      <td>/m/0cp05t9</td>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1941-11-18</td>\n",
       "      <td>M</td>\n",
       "      <td>1.730</td>\n",
       "      <td>/m/02w7gg</td>\n",
       "      <td>David Hemmings</td>\n",
       "      <td>15.0</td>\n",
       "      <td>/m/0g8ngmc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/022g44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450666</th>\n",
       "      <td>28308153</td>\n",
       "      <td>/m/0cp05t9</td>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roberta Paterson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0g8ngmj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0g8ngmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450667</th>\n",
       "      <td>28308153</td>\n",
       "      <td>/m/0cp05t9</td>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John Rogers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0g8ngmw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0btz19d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450668 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          975900   /m/03vyhn  2001-08-24                    Akooshay  \\\n",
       "0         975900   /m/03vyhn  2001-08-24  Lieutenant Melanie Ballard   \n",
       "1         975900   /m/03vyhn  2001-08-24         Desolation Williams   \n",
       "2         975900   /m/03vyhn  2001-08-24          Sgt Jericho Butler   \n",
       "3         975900   /m/03vyhn  2001-08-24             Bashira Kincaid   \n",
       "4         975900   /m/03vyhn  2001-08-24   Commander Helena Braddock   \n",
       "...          ...         ...         ...                         ...   \n",
       "450663    913762   /m/03pcrp  1992-05-21                      Elensh   \n",
       "450664    913762   /m/03pcrp  1992-05-21                      Hibiki   \n",
       "450665  28308153  /m/0cp05t9        1957                         NaN   \n",
       "450666  28308153  /m/0cp05t9        1957                         NaN   \n",
       "450667  28308153  /m/0cp05t9        1957                         NaN   \n",
       "\n",
       "        1958-08-26    F   1.62  Unnamed: 7      Wanda De Jesus    42  \\\n",
       "0       1974-08-15    F  1.780  /m/044038p  Natasha Henstridge  27.0   \n",
       "1       1969-06-15    M  1.727     /m/0x67            Ice Cube  32.0   \n",
       "2       1967-09-12    M  1.750         NaN       Jason Statham  33.0   \n",
       "3       1977-09-25    F  1.650         NaN         Clea DuVall  23.0   \n",
       "4       1949-05-26    F  1.727     /m/0x67           Pam Grier  52.0   \n",
       "...            ...  ...    ...         ...                 ...   ...   \n",
       "450663     1970-05    F    NaN         NaN  Dorothy Elias-Fahn   NaN   \n",
       "450664  1965-04-12    M    NaN         NaN       Jonathan Fahn  27.0   \n",
       "450665  1941-11-18    M  1.730   /m/02w7gg      David Hemmings  15.0   \n",
       "450666         NaN  NaN    NaN         NaN    Roberta Paterson   NaN   \n",
       "450667         NaN  NaN    NaN         NaN         John Rogers   NaN   \n",
       "\n",
       "        /m/0bgchxw  /m/0bgcj3x  /m/03wcfv7  \n",
       "0        /m/0jys3m  /m/0bgchn4   /m/0346l4  \n",
       "1        /m/0jys3g  /m/0bgchn_  /m/01vw26l  \n",
       "2       /m/02vchl6  /m/0bgchnq   /m/034hyc  \n",
       "3       /m/02vbb3r  /m/0bgchp9   /m/01y9xg  \n",
       "4       /m/02vdcfp  /m/0bgchnd   /m/0418ft  \n",
       "...            ...         ...         ...  \n",
       "450663  /m/0kr406c  /m/0kr406h   /m/0b_vcv  \n",
       "450664  /m/0kr405_  /m/0kr4090   /m/0bx7_j  \n",
       "450665  /m/0g8ngmc         NaN   /m/022g44  \n",
       "450666  /m/0g8ngmj         NaN  /m/0g8ngmm  \n",
       "450667  /m/0g8ngmw         NaN  /m/0btz19d  \n",
       "\n",
       "[450668 rows x 13 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with IMDB Director / Writer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roles = pd.read_table('./roles.tsv')\n",
    "# roles = roles.rename(columns={'directors':\"directors_imdb\", 'writers':'writers_imdb'})\n",
    "# movies = movies.merge(roles, left_on='id_imdb', right_on='tconst', how='inner')\n",
    "# movies = movies[['title','year','time','runtime','revenue','budget','rating','votes','id_wikipedia','id_freebase','id_imdb','languages','actors','crew','writers_imdb','directors','directors_imdb','production_companies','prod_country','is_hollywood_hof']]\n",
    "# movies['directors_imdb'].replace('\\\\N', None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(movies['directors_imdb'].isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with IMDB ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = pd.read_table('./ratings.tsv')\n",
    "# ratings = ratings.rename(columns={'averageRating':'rating_imdb', 'numVotes':'votes_imdb', 'tconst':'id_imdb'})\n",
    "# movies = movies.merge(ratings, on='id_imdb')\n",
    "# movies = movies.rename(columns={'rating':'rating_tmdb', 'votes':'votes_tmdb'})\n",
    "# movies = movies[['title','year','time','runtime', 'revenue', 'budget', 'rating_imdb', 'votes_imdb', 'rating_tmdb', 'votes_tmdb', 'id_wikipedia', 'id_freebase', 'id_imdb', 'languages', 'actors', 'crew', 'writers_imdb', 'directors', 'directors_imdb', 'production_companies', 'prod_country','is_hollywood_hof']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df\n",
    "movies.to_csv('movies_with_flag.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
